{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ocrpy Basic Usage Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocrpy import TextOcrPipeline\n",
    "from ocrpy import DocumentReader, StorageWriter, TextParser, TableParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch some sample Pdf and Image Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  sample_data/data.zip\n",
      "  inflating: sample_data/data/research paper 2.jpg  \n",
      "  inflating: sample_data/data/__MACOSX/._research paper 2.jpg  \n",
      "  inflating: sample_data/data/10.1.1.839.3147_removed.pdf  \n",
      "  inflating: sample_data/data/__MACOSX/._10.1.1.839.3147_removed.pdf  \n",
      "  inflating: sample_data/data/103-103-1-PB_removed.pdf  \n",
      "  inflating: sample_data/data/__MACOSX/._103-103-1-PB_removed.pdf  \n",
      "  inflating: sample_data/data/budget.jpg  \n",
      "  inflating: sample_data/data/__MACOSX/._budget.jpg  \n",
      "  inflating: sample_data/data/image.jpg  \n",
      "  inflating: sample_data/data/__MACOSX/._image.jpg  \n",
      "  inflating: sample_data/data/invoice.jpg  \n",
      "  inflating: sample_data/data/__MACOSX/._invoice.jpg  \n",
      "  inflating: sample_data/data/news 2.jpg  \n",
      "  inflating: sample_data/data/__MACOSX/._news 2.jpg  \n",
      "  inflating: sample_data/data/news.jpg  \n",
      "  inflating: sample_data/data/__MACOSX/._news.jpg  \n",
      "  inflating: sample_data/data/Odors_released_by_stressed_rats_produce.pdf  \n",
      "  inflating: sample_data/data/__MACOSX/._Odors_released_by_stressed_rats_produce.pdf  \n",
      "  inflating: sample_data/data/research paper.jpg  \n",
      "  inflating: sample_data/data/__MACOSX/._research paper.jpg  \n",
      "  inflating: sample_data/data/scansmpl.pdf  \n",
      "  inflating: sample_data/data/__MACOSX/._scansmpl.pdf  \n"
     ]
    }
   ],
   "source": [
    "# unzip the data\n",
    "!unzip sample_data/data.zip -d sample_data/data\n",
    "!mkdir sample_data/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the path for a sample pdf and image file and the parser backend\n",
    "DOC_PATH = \"sample_data/data/invoice.jpg\"\n",
    "PDF_PATH =  \"sample_data/data/Odors_released_by_stressed_rats_produce.pdf\"\n",
    "PARSER_BACKEND = \"pytesseract\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse text Data from a single file and write to a local storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS = {\"AWS\": \"path/to/aws-credentials.env/file\",\n",
    "               \"GCP\": \"path/to/gcp-credentials.json/file\"}\n",
    "               \n",
    "reader = DocumentReader(file=DOC_PATH) # read image or pdf file\n",
    "text_parser = TextParser(backend=PARSER_BACKEND, credentials={}) # Supported backends: pytesseract, google-cloud-vision, aws-textract. And you can also pass credentials for each backend if required.\n",
    "parsed_text = text_parser.parse(reader) # parse the document using the selected parser backend.\n",
    "\n",
    "writer = StorageWriter() # write to storage\n",
    "writer.write(parsed_text, \"sample_data/output/sample_image_output.json\") # write the parsed text to storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTED FULL TEXT:\n",
      " \n",
      "Page Lot\n",
      "\n",
      "Ecusta SAMPLE ORDER\n",
      "\n",
      "a division of P. H. GLATFELTER COMPANY tia,__047503.\n",
      "[PSGAH VOREST, NORTH CAROLINA 2768 “HLEPHONE: 7056772211\n",
      "reouesteo [ “7 [sa ro “7\n",
      "ev Mr. Glenn E. Creamer Mr. Kenneth Wayne Smith\n",
      "R, J. Reynolds Tobacco Company R. J. Reynolds Tobacco Company\n",
      "Bowman Gray Technical Center Bowman Gray Technical Center\n",
      "P. 0. Box 1487 950 Reynolds Boulevard\n",
      "Winston-Salem, North Carolina Winston-Salem, North Carolina\n",
      "L. 27102 _| L_ 27105_|\n",
      "CHARGE DATE DATE DATE 10, bare | sappe [ROUTING\n",
      "fuser | entero | soveomeo | supenc | suipreo | pro 1 cot\n",
      "3022-9461] 4/13/95] 4/20/99] 4/17/95 | 4/17/95] x United Parcel Service\n",
      "eu ‘ounnrry . se roovet yuan\n",
      "1 | 2 Bobbin 27 mm x 6000 N | TOD 07550, Low Sidestream Cigarette 1\n",
      "\n",
      "Paper, 25 g/M? Basis Weight, Wood\n",
      "Pulp, 28% Calcium Carbonate, 3%\n",
      "Magnesium Hydroxide, 0.4% Citrates\n",
      "\n",
      "‘SAMPLES - NO COWMERGIAL VALUE - VALUE FO CUSTOMS PURPOSES ONLY: LESS THAN US, $1000 2\n",
      "8\n",
      "MARKS: SAMPLES - NO COMMERCIAL VALUE CERTIFIED TRUE AND CORRECT ®\n",
      "Gross xuos__11__pounos Ns\n",
      "a\n",
      "\n",
      "ner Kos ___2__pounos ————\n",
      "MADE IN USA ‘AUTHORIZED RENT\n",
      "\n",
      "EXPORT LICENSE GENERAL LICENSE G - DEST\n",
      "EXPORT LICENSE NOT REQUIRED\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extracted text from the image\n",
    "print(\"EXTRACTED FULL TEXT:\\n \")\n",
    "print(parsed_text[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Table Data from a single file and write to a local storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DocumentReader(file='sample_data/data/Odors_released_by_stressed_rats_produce.pdf', credentials=None, storage_type='LOCAL')\n"
     ]
    }
   ],
   "source": [
    "aws_config = \"../notebooks/local/aws_keys.env\"\n",
    "\n",
    "reader = DocumentReader(file=PDF_PATH) # read document\n",
    "\n",
    "table_parser = TableParser(credentials=aws_config) # Table parser\n",
    "parsed_table = table_parser.parse(reader,  attempt_csv_conversion=True) # parse the document using the selected parser backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parsed table is a dictionary of pandas dataframes. (each item represents an individual table in a pdf document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0 has 0 tables\n",
      "Page 1 has 2 tables\n",
      "Page 2 has 0 tables\n"
     ]
    }
   ],
   "source": [
    "for page, tables in parsed_table.items():\n",
    "    print(f\"Page {page} has {len(tables)} tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Latency (in</td>\n",
       "      <td>min)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Group</td>\n",
       "      <td>n</td>\n",
       "      <td>M</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Experiment 1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>12</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stress</td>\n",
       "      <td>12</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Experiment 2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Control</td>\n",
       "      <td>4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stress</td>\n",
       "      <td>5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Experiment 3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Control</td>\n",
       "      <td>8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Conspecific</td>\n",
       "      <td>8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Novelty</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stress</td>\n",
       "      <td>8</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Experiment 4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Control-NaCI</td>\n",
       "      <td>8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Control-naltrexone</td>\n",
       "      <td>8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stress-NaCl</td>\n",
       "      <td>8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Stress-naltrexone</td>\n",
       "      <td>8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0   1            2     3\n",
       "0                           Latency (in  min)\n",
       "1                Group   n            M    SE\n",
       "2         Experiment 1                       \n",
       "3              Control  12          6.6   1.3\n",
       "4               Stress  12         10.9   1.2\n",
       "5         Experiment 2                       \n",
       "6              Control   4          4.4   1.7\n",
       "7               Stress   5         10.5   0.4\n",
       "8         Experiment 3                       \n",
       "9              Control   8          5.9   1.6\n",
       "10         Conspecific   8          7.7   1.6\n",
       "11             Novelty   8          5.0   1.6\n",
       "12              Stress   8         12.4   0.7\n",
       "13        Experiment 4                       \n",
       "14        Control-NaCI   8          3.7   0.6\n",
       "15  Control-naltrexone   8          4.9   1.3\n",
       "16         Stress-NaCl   8         11.1   1.6\n",
       "17   Stress-naltrexone   8          4.1   1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_table[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Behavior</td>\n",
       "      <td>Control</td>\n",
       "      <td>Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Formalin induced</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rearing</td>\n",
       "      <td>41</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Freezing</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grooming</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>General activity</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1       2\n",
       "0          Behavior  Control  Stress\n",
       "1  Formalin induced        5       1\n",
       "2           Rearing       41      28\n",
       "3          Freezing        1       2\n",
       "4          Grooming        6       8\n",
       "5  General activity       47      61"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_table[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text extraction via Pipeline API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Pipeline with the following configuration:\n",
      "\n",
      "1. DOCUMENT_SOURCE: sample_data\n",
      "2. DOCUMENT_DESTINATION: output\n",
      "3. SOURCE_STORAGE_TYPE: LOCAL\n",
      "4. DESTINATION_STORAGE_TYPE: LOCAL\n",
      "5. PARSER_BACKEND_TYPE: pytesseract\n",
      "6. TOTAL_DOCUMENT_COUNT: 13\n",
      "7. IMAGE_FILE_COUNT: 7\n",
      "8. PDF_FILE_COUNT: 4\n",
      "9. CREDENTIALS: {'AWS': 'path/to/aws-credentials.env/file', 'GCP': 'path/to/gcp-credentials.json/file'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:11,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE: .DS_Store - ERROR: 'FileTypeNotSupported' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:43, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE: output - ERROR: 'FileTypeNotSupported' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [01:57,  9.02s/it]\n"
     ]
    }
   ],
   "source": [
    "SOURCE = 'sample_data/data' # s3 bucket or local directory or gcs bucket with your documents.\n",
    "DESTINATION = 'sample_data/output/' # s3 bucket or local directory or gcs bucket to write the processed documents.\n",
    "PARSER = 'pytesseract' # or 'google-cloud-vision' or 'pytesseract'\n",
    "CREDENTIALS = {\"AWS\": \"path/to/aws-credentials.env/file\",\n",
    "               \"GCP\": \"path/to/gcp-credentials.json/file\"} # optional - if you are using any cloud service.\n",
    "\n",
    "pipeline = TextOcrPipeline(source_dir=SOURCE, destination_dir=DESTINATION,\n",
    "                           parser_backend=PARSER, credentials_config=CREDENTIALS)\n",
    "pipeline.process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f13271a8eedf9748f2b15eecb4f6b6588fa78e9defad529da5fcd33ad9fd96c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
